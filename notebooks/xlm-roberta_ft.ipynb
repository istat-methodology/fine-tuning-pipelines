{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf8oxhMAGygC"
      },
      "source": [
        "# Multilingual RoBERTa (XLM-R) Fine Tuning\n",
        "This notebook explores fine-tuning Multilingual RoBERTa (XLM-R) for text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mymhgZshGxG6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from dotenv import load_dotenv\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTct_UKHHN8C"
      },
      "source": [
        "## Configs\n",
        "Here, we can set some parameters for importing and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E6gLBQsHOoT"
      },
      "outputs": [],
      "source": [
        "model_version : str   = 'base'\n",
        "model_id      : str   = f'FacebookAI/xlm-roberta-{model_version}'\n",
        "dataset_id    : str   = 'istat-ai/hs_dataset'\n",
        "num_labels    : int   = 2\n",
        "\n",
        "output_dir    : str   = f'saved_models/xlm-r-{model_version}'\n",
        "epochs        : int   = 10\n",
        "learn_rate    : float = 2e-5\n",
        "scheduler     : str   = 'linear'\n",
        "train_bs      : int   = 16\n",
        "eval_bs       : int   = 32\n",
        "ga_steps      : int   = 2\n",
        "decay         : float = 0.01\n",
        "warmup        : float = 0.1\n",
        "log_steps     : int   = 10\n",
        "eval_strategy : str   = 'epoch'\n",
        "save_strategy : str   = 'epoch'\n",
        "fp16          : bool  = True\n",
        "load_best     : bool  = True\n",
        "report_to     : list  = []\n",
        "log_level     : str   = 'warning'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1bdsbciJcOq"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YulW0TjVJp0T"
      },
      "source": [
        "## Load the Model\n",
        "Load the model and tokenizer from huggingface. If the model is gated or private, you need to set an environment variable called `\"HF_TOKEN\"` that contans your huggingface token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcCjygt2JobE"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_labels\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAXvVU_aJwjd"
      },
      "source": [
        "## Data Preprocessing\n",
        "Load the data from huggingface. The data should have a `text` column and a `label` column that comprises numerical labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtAt9LGHJ7_T"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(dataset_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BpN5dbkLdQz"
      },
      "source": [
        "Now we tokenize and pad the data using the pretrained tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlncIlcGLf0m"
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], padding=True, truncation=True, max_length=tokenizer.model_max_length)\n",
        "\n",
        "tokenized_data = data.map(\n",
        "    tokenize,\n",
        "    batched=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylxtqrKLnuWk"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7cb4XGAL0ua"
      },
      "source": [
        "## Training\n",
        "First, we define a function to compute the metrics that we want to monitor during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhwUIeK0L1cy"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {'accuracy': accuracy, 'f1_macro': f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKU1AeFmMf76"
      },
      "source": [
        "Now, we define the training arguments and the trainer class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmrm6EqwMim2"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    learning_rate=learn_rate,\n",
        "    lr_scheduler_type=scheduler,\n",
        "    per_device_train_batch_size=train_bs,\n",
        "    per_device_eval_batch_size=eval_bs,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    warmup_ratio=warmup,\n",
        "    weight_decay=decay,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=log_steps,\n",
        "    eval_strategy=eval_strategy,\n",
        "    save_strategy=save_strategy,\n",
        "    fp16=fp16,\n",
        "    load_best_model_at_end=load_best,\n",
        "    report_to=report_to,\n",
        "    log_level=log_level,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data['train'],\n",
        "    eval_dataset=tokenized_data['eval'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LyUbBgmNcTV"
      },
      "source": [
        "Finally, we can start training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzfvlgnkNdys"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01H5qqTAlPfF"
      },
      "source": [
        "## Evaluation\n",
        "Now, we can evaluate the model on our test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWbBDbR8lR7V"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate(tokenized_data['test'])\n",
        "print(eval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
