{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "id": "_RCx0BO2beP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ModernBERT Fine-Tuning\n",
        "This notebook explores fine-tuning ModernBERT for text classification."
      ],
      "metadata": {
        "id": "OUYoznkbZx8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wq3FPsnZonE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from dotenv import load_dotenv\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Configs\n",
        "Here, we can set some parameters for importing and training."
      ],
      "metadata": {
        "id": "wNx4Qc4saCBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_version : str   = 'base'\n",
        "model_id      : str   = f'answerdotai/ModernBERT-{model_version}'\n",
        "dataset_id    : str   = 'istat-ai/hs_dataset'\n",
        "num_labels    : int   = 2\n",
        "max_seq_len   : int   = 1024\n",
        "\n",
        "output_dir    : str   = f'saved_models/ModernBERT-{model_version}'\n",
        "epochs        : int   = 10\n",
        "learn_rate    : float = 2e-5\n",
        "scheduler     : str   = 'linear'\n",
        "train_bs      : int   = 16\n",
        "eval_bs       : int   = 32\n",
        "ga_steps      : int   = 2\n",
        "decay         : float = 0.01\n",
        "warmup        : float = 0.1\n",
        "log_steps     : int   = 10\n",
        "eval_strategy : str   = 'epoch'\n",
        "save_strategy : str   = 'epoch'\n",
        "fp16          : bool  = True\n",
        "load_best     : bool  = True\n",
        "report_to     : list  = []\n",
        "log_level     : str   = 'warning'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "u5PP9m-JaFTL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "gzAWBBFFc48K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Model\n",
        "Load the model and tokenizer from huggingface. If the model is gated or private, you need to set an environment variable called `\"HF_TOKEN\"` that contans your huggingface token."
      ],
      "metadata": {
        "id": "buOJdADZabPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_labels\n",
        ").to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "fZ9qJTWdafnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "Load the data from huggingface. The data should have a `text` column and a `label` column that comprises numerical labels.\n"
      ],
      "metadata": {
        "id": "IZFzRzEDb8HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_dataset(dataset_id)"
      ],
      "metadata": {
        "id": "pTpzgEZHb_cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we tokenize and pad the data using the pretrained tokenizer."
      ],
      "metadata": {
        "id": "4lBFOGYscDwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], padding=True, truncation=True, max_length=max_seq_len)\n",
        "\n",
        "tokenized_data = data.map(\n",
        "    tokenize,\n",
        "    batched=True\n",
        ")"
      ],
      "metadata": {
        "id": "p-jTJeHicFs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "uP5I6MCQceRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "First, we define a function to compute the metrics that we want to monitor during training.\n"
      ],
      "metadata": {
        "id": "D6tXvrB7cgUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='macro')\n",
        "    return {'accuracy': accuracy, 'f1_macro': f1}"
      ],
      "metadata": {
        "id": "DPSKJRi5cfGk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we define the training arguments and the trainer class."
      ],
      "metadata": {
        "id": "WVIn5sbVcnUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=epochs,\n",
        "    learning_rate=learn_rate,\n",
        "    lr_scheduler_type=scheduler,\n",
        "    per_device_train_batch_size=train_bs,\n",
        "    per_device_eval_batch_size=eval_bs,\n",
        "    gradient_accumulation_steps=ga_steps,\n",
        "    warmup_ratio=warmup,\n",
        "    weight_decay=decay,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=log_steps,\n",
        "    eval_strategy=eval_strategy,\n",
        "    save_strategy=save_strategy,\n",
        "    fp16=fp16,\n",
        "    load_best_model_at_end=load_best,\n",
        "    report_to=report_to,\n",
        "    log_level=log_level,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data['train'],\n",
        "    eval_dataset=tokenized_data['eval'],\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "Tfa1_RUMcovv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can start training the model."
      ],
      "metadata": {
        "id": "9IOYFH_lcujp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "-0f-DuIGcux0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Now, we can evaluate the model on our test set."
      ],
      "metadata": {
        "id": "rPUQbvqMc7n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate(tokenized_data['test'])\n",
        "print(eval_results)"
      ],
      "metadata": {
        "id": "JGLIvhPXc834"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}